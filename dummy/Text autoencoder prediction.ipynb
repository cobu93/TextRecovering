{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torchtext\n",
    "import collections\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify if CUDA is available"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CUDA devices:\n\t0 - GeForce RTX 2060\n"
    }
   ],
   "source": [
    "# If CUDA is available print devices\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA devices:')\n",
    "    for device in range(0, torch.cuda.device_count()):\n",
    "        print('\\t{} - {}'.format(device, torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print('No CUDA devices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define encoder and decoder"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, embedding_size, encoding_size, use_cuda=False):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.encoding_size = encoding_size\n",
    "   \n",
    "    self.encoder = nn.LSTM(\n",
    "      input_size=embedding_size, \n",
    "      hidden_size=encoding_size,\n",
    "      num_layers=1,\n",
    "      bias=True,\n",
    "      batch_first=True,\n",
    "      dropout=0.1,\n",
    "      bidirectional=False\n",
    "    )\n",
    "  \n",
    "  def forward(self, embeddings):\n",
    "    _, (hidden, memory) = self.encoder(embeddings)\n",
    "    return hidden, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "  def __init__(self, encoding_size, embedding_size, use_cuda=False):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "\n",
    "    self.encoding_size = encoding_size\n",
    "\n",
    "    self.decoder = nn.LSTM(\n",
    "      input_size=embedding_size, \n",
    "      hidden_size=encoding_size,\n",
    "      num_layers=1,\n",
    "      bias=True,\n",
    "      batch_first=True,\n",
    "      dropout=0.1,\n",
    "      bidirectional=False\n",
    "    )\n",
    "\n",
    "    self.dim_linear = nn.Linear(encoding_size, embedding_size)\n",
    "    self.dim_fn = nn.Tanh()    \n",
    "\n",
    "  def forward(self, embeddings, init_hidden, init_memory):\n",
    "\n",
    "    output_, (hidden, memory) = self.decoder(embeddings, (init_hidden, init_memory))\n",
    "    linear = self.dim_linear(output_)\n",
    "    \n",
    "    return self.dim_fn(linear), hidden, memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions related with transforming data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform each sentence by adding a start and finish sequence for encoder and decoder training\n",
    "def get_transformation(vocabulary, embedding_size):\n",
    "    first_embedding = torch.ones((embedding_size,))\n",
    "    last_embedding = torch.zeros((embedding_size,))\n",
    "\n",
    "    def transform_example(example):\n",
    "        transformed = []\n",
    "        transformed.append(first_embedding)\n",
    "\n",
    "        for idx in example:\n",
    "            transformed.append(vocabulary.vectors[idx])\n",
    "        \n",
    "        transformed.append(last_embedding)\n",
    "        \n",
    "        transformed = torch.stack(transformed)[:15]\n",
    "        transformed = transformed.unsqueeze(0)\n",
    "\n",
    "        return transformed\n",
    "\n",
    "    return transform_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices from word's vectors\n",
    "def get_index_fn(vectors):\n",
    "    def get_index(prediction):\n",
    "        indices = []\n",
    "\n",
    "        for vector in prediction:\n",
    "            result = torch.abs(vectors - vector).norm(2, dim=1)\n",
    "            indices.append(torch.argmin(result))\n",
    "\n",
    "        indices = torch.stack(indices)\n",
    "        return indices\n",
    "\n",
    "    return get_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function recover a sentence from word's indices\n",
    "def get_text_fn(itos):\n",
    "    def get_text(example):\n",
    "        text = []\n",
    "        for idx in example:\n",
    "            text.append(itos[idx])\n",
    "\n",
    "        return ' '.join(text)\n",
    "    return get_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function return indices from string\n",
    "def get_example_fn(stoi):\n",
    "    def get_example(string):\n",
    "        parts = re.sub(r'(\\s|\\-|\\]|\\^|\\$|\\*|\\.|\\\\|\\'|,|\")', r'#\\1#', string)\n",
    "        parts = re.sub('(#|\\s)+', '#', parts)\n",
    "        parts = parts.split('#')\n",
    "\n",
    "        example = []\n",
    "        for part in parts:\n",
    "            if part in stoi:\n",
    "                example.append(stoi[part])\n",
    "            else:\n",
    "                example.append(stoi['<unk>'])\n",
    "\n",
    "        return example\n",
    "    return get_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define variables related with loading information and training/validation data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORS_LOADED = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading word vectors and trainig/validation dataset"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = torchtext.vocab.FastText(language='en', max_vectors=VECTORS_LOADED, cache='../.vector_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = torchtext.vocab.Vocab(collections.Counter(fasttext.stoi.keys()))\n",
    "vocabulary.set_vectors(fasttext.stoi, fasttext.vectors, fasttext.dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining variables related with training"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "EMBEDDING_SIZE = fasttext.dim\n",
    "ENCODING_SIZE = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load encoder and decoder"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(EMBEDDING_SIZE, ENCODING_SIZE, use_cuda=USE_CUDA)\n",
    "encoder.load_state_dict(torch.load('checkpoints/encoder.pt'))\n",
    "encoder.eval()\n",
    "decoder = Decoder(ENCODING_SIZE, EMBEDDING_SIZE, use_cuda=USE_CUDA)\n",
    "decoder.load_state_dict(torch.load('checkpoints/decoder.pt'))\n",
    "decoder.eval()\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_fn = get_transformation(vocabulary, EMBEDDING_SIZE)\n",
    "get_text = get_text_fn(vocabulary.itos)\n",
    "get_indices = get_index_fn(vocabulary.vectors)\n",
    "get_example = get_example_fn(vocabulary.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting (Recovering)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_TEXT = 'He has called on authorities in Iran to restore the internet service'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = get_example(ORIGINAL_TEXT.lower())\n",
    "embeddings = transformation_fn(example)\n",
    "\n",
    "with torch.no_grad():\n",
    "    if USE_CUDA:\n",
    "        embeddings = embeddings.cuda()\n",
    "    \n",
    "    representation, memory = encoder(embeddings[:,1:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, representation contains the encoded sentence"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[[ 0.0029, -0.0010, -0.0162,  ..., -0.2869, -0.0137, -0.6091]]],\n       device='cuda:0')"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoding"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.ones((1, 1, EMBEDDING_SIZE))\n",
    "hidden = representation\n",
    "mem = memory\n",
    "decodings = []\n",
    "\n",
    "if USE_CUDA:\n",
    "    embedding = embedding.cuda()\n",
    "    hidden = hidden.cuda()\n",
    "    mem = mem.cuda()\n",
    "\n",
    "for prediction_idx in range(15):\n",
    "    embedding, hidden, mem = decoder(embedding, hidden, mem)\n",
    "    decodings.append(embedding[0])\n",
    "\n",
    "decodings = torch.stack(decodings)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'and has called on authorities in iran to but the the internet service <pad> and'"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "get_text(get_indices(decodings.cpu()))"
   ]
  }
 ]
}