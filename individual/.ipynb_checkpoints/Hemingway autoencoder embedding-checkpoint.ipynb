{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torchtext\n",
    "import collections\n",
    "\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA devices:\n",
      "\t0 - GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "# If CUDA is available print devices\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA devices:')\n",
    "    for device in range(0, torch.cuda.device_count()):\n",
    "        print('\\t{} - {}'.format(device, torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print('No CUDA devices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  def __init__(self, embedding_size, encoding_size, embedding_layer, use_cuda=False):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.encoding_size = encoding_size    \n",
    "    self.embedding = embedding_layer\n",
    "    \n",
    "    self.encoder = nn.GRU(\n",
    "      input_size=embedding_size, \n",
    "      hidden_size=encoding_size,\n",
    "      dropout=0.2,\n",
    "      num_layers=3,\n",
    "      bias=True,\n",
    "      batch_first=True,\n",
    "      bidirectional=False\n",
    "    )\n",
    "  \n",
    "  def forward(self, words_indices):\n",
    "    embeddings = self.embedding(words_indices)\n",
    "    _, hidden  = self.encoder(embeddings)\n",
    "    return hidden, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "  def __init__(self, encoding_size, embedding_size, embedding_layer, vocab_size, use_cuda=False):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.encoding_size = encoding_size\n",
    "    self.embedding = embedding_layer\n",
    "\n",
    "    self.decoder = nn.GRU(\n",
    "      input_size=embedding_size, \n",
    "      hidden_size=encoding_size,\n",
    "      dropout=0.2,\n",
    "      num_layers=3,\n",
    "      bias=True,\n",
    "      batch_first=True,\n",
    "      bidirectional=False\n",
    "    )\n",
    "\n",
    "    self.dim_linear = nn.Linear(encoding_size, vocab_size)\n",
    "    self.dim_fn = nn.ReLU()    \n",
    "\n",
    "  def forward(self, words_indices, init_hidden, init_memory):\n",
    "    with torch.no_grad():\n",
    "        embeddings = self.embedding(words_indices)\n",
    "        \n",
    "    output_, _ = self.decoder(embeddings, init_hidden)\n",
    "    linear = self.dim_fn(self.dim_linear(output_))\n",
    "    \n",
    "    return linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining functions related with transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function recover a sentence from word's indices\n",
    "def get_text_fn(vocab):\n",
    "    itos = {}\n",
    "    for word in vocab:\n",
    "        itos[vocab[word]] = word\n",
    "        \n",
    "    def get_text(example):\n",
    "        text = []\n",
    "        for idx in example:\n",
    "            text.append(itos[idx])\n",
    "\n",
    "        return ' '.join(text)\n",
    "    return get_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define variables related with loading information and training/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_PARTITION = 0.3 \n",
    "EXAMPLES_PER_EPOCH = 1\n",
    "BATCH_SIZE = 8\n",
    "DATASET_FILENAME = '../datasets/books_dataset.pk'\n",
    "CHECKPOINT_BASE = 'checkpoints'\n",
    "ENCODER_CHECKPOINT_FILE = 'Hemingway_encoder'\n",
    "DECODER_CHECKPOINT_FILE = 'Hemingway_decoder'\n",
    "AUTHOR = 'Ernest Hemingway'\n",
    "\n",
    "# Keys for dictionary\n",
    "MEAN_KEY = 'SentenceLengthMean'\n",
    "DATASET_KEY = 'Dataset'\n",
    "AUTHOR_KEY = 'Author'\n",
    "BOOKS_KEY = 'Books'\n",
    "DATASET_SENTENCES_MEAN = 'SentenceLengthMean'\n",
    "BOOKS_PATH_KEY = 'Path'\n",
    "BOOK_CONTENT_KEY = 'Content'\n",
    "BOOK_SENTENCES_KEY = 'Sentences'\n",
    "BOOK_SENTENCES_HIST_KEY = 'SentenceLengthHist'\n",
    "BOOK_SENTENCES_MEAN = 'SentenceLengthMean'\n",
    "\n",
    "PAD_CHAR = '<pad>'\n",
    "UNKNOWN_CHAR = '<unk>'\n",
    "START_CHAR = '<str>'\n",
    "END_CHAR = '<end>'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading word vectors and trainig/validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data, \n",
    "        vocabulary,\n",
    "        unknown_char=UNKNOWN_CHAR, \n",
    "        pad_char=PAD_CHAR, \n",
    "        start_char=START_CHAR, \n",
    "        end_char=END_CHAR\n",
    "    ):\n",
    "        # Defines dataset\n",
    "        self.data = []\n",
    "        \n",
    "        # For all sentences\n",
    "        for sentence in data:\n",
    "            # Add start character\n",
    "            example = [vocabulary[start_char]]\n",
    "                       \n",
    "            for word in sentence:\n",
    "                if word not in vocabulary:\n",
    "                    example.append(vocabulary[unknown_char])\n",
    "                else:\n",
    "                    example.append(vocabulary[word])\n",
    "                    \n",
    "            # Add end character\n",
    "            example.append(vocabulary[end_char])\n",
    "            self.data.append(example)\n",
    "            \n",
    "        self.data = torch.LongTensor(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all authors datasets\n",
    "with open(DATASET_FILENAME, 'rb') as f:\n",
    "    datasets = pickle.load(f)\n",
    "\n",
    "# Find current author dataset\n",
    "dataset = None\n",
    "for ds in datasets[DATASET_KEY]:\n",
    "    if ds[AUTHOR_KEY] == AUTHOR:\n",
    "        dataset = ds\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates vocabulary\n",
    "vocab = {UNKNOWN_CHAR: 0, PAD_CHAR: 1, START_CHAR: 2, END_CHAR: 3}\n",
    "\n",
    "# Get sentences mean of author's books\n",
    "sentence_length = math.ceil(dataset[DATASET_SENTENCES_MEAN])\n",
    "\n",
    "# Join books of same author in a unique dataset\n",
    "full_dataset = []\n",
    "for book in dataset[BOOKS_KEY]:\n",
    "    # Balance sentences length to their mean\n",
    "    for sentence in book[BOOK_SENTENCES_KEY]:\n",
    "        balanced_sentence = [word.lower().strip() for word in sentence[:sentence_length]]\n",
    "        balanced_sentence.extend([PAD_CHAR] * (sentence_length - len(balanced_sentence)))\n",
    "        full_dataset.append(balanced_sentence)\n",
    "\n",
    "# Shuffle dataset\n",
    "random.shuffle(full_dataset)\n",
    "\n",
    "# Partition and creation of training and validation datasets\n",
    "partition_idx = math.floor(len(full_dataset) * (1 - VAL_PARTITION))\n",
    "\n",
    "# Build vocab with training set\n",
    "for sentence in full_dataset[:partition_idx]:\n",
    "    for word in sentence:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "train_dataset = BookDataset(full_dataset[:partition_idx], vocab)\n",
    "test_dataset = BookDataset(full_dataset[partition_idx:], vocab)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining variables related with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "EMBEDDING_SIZE = 300\n",
    "ENCODING_SIZE = 2048\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 50\n",
    "VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(VOCAB_SIZE, EMBEDDING_SIZE)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining training components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoints found. New training.\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(EMBEDDING_SIZE, ENCODING_SIZE, embedding_layer, use_cuda=USE_CUDA)\n",
    "decoder = Decoder(ENCODING_SIZE, EMBEDDING_SIZE, embedding_layer, VOCAB_SIZE, use_cuda=USE_CUDA)\n",
    "\n",
    "try:\n",
    "    encoder.load_state_dict(torch.load(os.path.join(CHECKPOINT_BASE, ENCODER_CHECKPOINT_FILE + '.pt')))\n",
    "    decoder.load_state_dict(torch.load(os.path.join(CHECKPOINT_BASE, DECODER_CHECKPOINT_FILE + '.pt')))\n",
    "except:\n",
    "    print('No checkpoints found. New training.')\n",
    "    pass\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_function():\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "    \n",
    "    def my_loss_fn(target, predicted):\n",
    "        predicted_size = predicted.size()\n",
    "        flatten_size = predicted_size[0] * predicted_size[1]\n",
    "        \n",
    "        target_ = target.reshape([flatten_size])\n",
    "        predicted_ = predicted.reshape([flatten_size, predicted_size[2]])\n",
    "        return loss_fn(predicted_, target_)\n",
    "    \n",
    "    return my_loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()), \n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(0.1, 0.999)\n",
    ")\n",
    "\n",
    "loss_fn = get_loss_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text = get_text_fn(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(encoder, decoder, loss_fn, optimizer, batch, use_cuda):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    if use_cuda:\n",
    "      batch = batch.cuda()\n",
    "\n",
    "    encoder.zero_grad()\n",
    "    decoder.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    representation, memory = encoder(batch[:,1:])\n",
    "    \n",
    "    if use_cuda:\n",
    "      representation = representation.cuda()\n",
    "      memory = memory.cuda()\n",
    "    \n",
    "    decodings = decoder(batch[:,:-1], representation, memory)\n",
    "    loss = loss_fn(batch[:,1:], decodings)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(encoder, decoder, loss_fn, batch, use_cuda):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        if use_cuda:\n",
    "            batch = batch.cuda()\n",
    "\n",
    "        representation, memory = encoder(batch[:,1:])\n",
    "\n",
    "        if use_cuda:\n",
    "            representation = representation.cuda()\n",
    "            memory = memory.cuda()\n",
    "        \n",
    "        decodings = decoder(batch[:,:-1], representation, memory)\n",
    "\n",
    "        loss = loss_fn(batch[:,1:], decodings)\n",
    "\n",
    "        return loss.item(), decodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for history\n",
    "train_loss_history = []\n",
    "val_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** EPOCH 0 ***************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed01949d50e1449590d7d4cf5ac208a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=207.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real: <str> maybe it will open with the sun , he thought <pad> <pad> <pad> <pad> <pad> <pad> <pad> <end>\n",
      "Decoded: began teetered teetered baseball baseball baseball motion motion joe joe several right right effectively horned horned yet yet\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce1545cce2b47f8a56585e75a3c02eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=89.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*************************** EPOCH 1 ***************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bb9de875f5467684999ed2049f76b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=207.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real: <str> i spoke to him about the <unk> in milano <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <end>\n",
      "Decoded: he he the <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bf18a840a940d098b01a09dca60b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=89.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*************************** EPOCH 2 ***************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cb91cb19344434999d0095964ca1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=207.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real: <str> “ sure is hell <unk> it down , joe ” he ’ d say and <unk> back <end>\n",
      "Decoded: he he the the the the the the the the the the the the the the the the\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238652c8bff3490ea9253350c4bf785c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=89.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*************************** EPOCH 3 ***************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e265661e7b4a82ae4678cb3f68164c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=207.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real: <str> \" it was only his turn , \" he said <pad> <pad> <pad> <pad> <pad> <pad> <pad> <end>\n",
      "Decoded: \" he was the the the the the <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-27ce2b7fac19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Train step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-9f836d083b79>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(encoder, decoder, loss_fn, optimizer, batch, use_cuda)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdecodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepresentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecodings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ML/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define steps where examples will be sampled \n",
    "example_step = math.floor(len(train_dataloader) / EXAMPLES_PER_EPOCH)\n",
    "test_examples = iter(test_dataloader)\n",
    "\n",
    "\n",
    "last_val_loss = None\n",
    "\n",
    "# For EPOCHS\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "  print('*************************** EPOCH {} ***************************'.format(epoch))\n",
    "\n",
    "  # Restart train and validation datasets\n",
    "  examples = iter(train_dataloader)\n",
    "\n",
    "  # Progress bar for training dataset\n",
    "  progress_bar = tqdm(range(len(train_dataloader)))\n",
    "  train_loss = 0\n",
    "  \n",
    "  # For all data in training dataset\n",
    "  \n",
    "  for batch_idx in progress_bar:\n",
    "\n",
    "    # Add train loss to progress bar\n",
    "    progress_bar.set_description('Loss: {}'.format(train_loss / (batch_idx + 1)))\n",
    "    \n",
    "    # Train step\n",
    "    example = next(examples)\n",
    "    train_loss += train_step(encoder, decoder, loss_fn, optimizer, example, USE_CUDA)\n",
    "\n",
    "\n",
    "    if batch_idx % example_step == 0:\n",
    "      with torch.no_grad():\n",
    "        try:\n",
    "          example = next(test_examples)\n",
    "        except:\n",
    "          test_examples = iter(test_dataloader)\n",
    "          example = next(test_examples)\n",
    "\n",
    "        _, decodings = val_step(encoder, decoder, loss_fn, example, USE_CUDA)\n",
    "        \n",
    "        decodings = torch.argmax(decodings[0], dim=-1).cpu().numpy()\n",
    "\n",
    "        print('\\nReal: {}'.format(get_text(example[0].numpy())))\n",
    "        print('Decoded: {}'.format(get_text(decodings)))\n",
    "\n",
    "  \n",
    "  val_examples = iter(test_dataloader)\n",
    "  with torch.no_grad():\n",
    "    progress_bar = tqdm(range(len(test_dataloader)))\n",
    "    val_loss = 0\n",
    "\n",
    "    for batch_idx in progress_bar:\n",
    "      progress_bar.set_description('Val loss: {}'.format(val_loss / (batch_idx + 1)))\n",
    "      example = next(val_examples)\n",
    "\n",
    "      val_loss += val_step(encoder, decoder, loss_fn, example, USE_CUDA)[0]\n",
    "       \n",
    "\n",
    "    if last_val_loss is None or val_loss < last_val_loss:\n",
    "      last_val_loss = val_loss\n",
    "\n",
    "      torch.save(encoder.state_dict(), os.path.join(CHECKPOINT_BASE, ENCODER_CHECKPOINT_FILE + '_{}.pt').format(epoch))\n",
    "      torch.save(decoder.state_dict(), os.path.join(CHECKPOINT_BASE, DECODER_CHECKPOINT_FILE + '_{}.pt').format(epoch))\n",
    "    \n",
    "  train_loss_history.append(train_loss / len(train_dataloader))\n",
    "  val_loss_history.append(val_loss / len(test_dataloader))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [epoch for epoch in range(EPOCHS)]\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "plt.plot(x, train_loss_history, label='Training loss')\n",
    "plt.plot(x, val_loss_history, label='Validation loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
