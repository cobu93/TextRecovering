{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "from text.utils import load_text_state, split_sentences\n",
    "from model.utils import get_device, load_model_state\n",
    "from text_model import TextModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_BASE = 'checkpoints'\n",
    "AUTHORS = ['Ernest Hemingway', 'Friedrich Nietzsche', 'Oscar Wilde']\n",
    "SENTENCES_LENGTHS = [15, 27, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text checkpoint loaded for Ernest Hemingway\n",
      "Text checkpoint loaded for Friedrich Nietzsche\n",
      "Text checkpoint loaded for Oscar Wilde\n"
     ]
    }
   ],
   "source": [
    "vocabs = []\n",
    "\n",
    "for author in AUTHORS:\n",
    "    vocab, _, _ = load_text_state(os.path.join(CHECKPOINT_BASE, author + '_text.pk'))    \n",
    "    vocabs.append(vocab)\n",
    "    \n",
    "    print('Text checkpoint loaded for {}'.format(author))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "BETA_1 = 0.1\n",
    "BETA_2 = 0.999\n",
    "EPOCHS = 50\n",
    "NUM_HEADS = 8\n",
    "ENCODER_LAYERS = 1\n",
    "DECODER_LAYERS = 1\n",
    "EMBEDDING_SIZE = 512\n",
    "FF_DIM = 1024\n",
    "DROPOUT=0.1\n",
    "STEP_LR_DECAY = 15\n",
    "LR_FACTOR_DECAY = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint loaded for Ernest Hemingway\n",
      "Model checkpoint loaded for Friedrich Nietzsche\n",
      "Model checkpoint loaded for Oscar Wilde\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for idx, author in enumerate(AUTHORS):\n",
    "    model = TextModel(\n",
    "        vocab_size=len(vocabs[idx]),\n",
    "        embedding_size=EMBEDDING_SIZE, \n",
    "        num_heads=NUM_HEADS, \n",
    "        encoder_layers=ENCODER_LAYERS, \n",
    "        decoder_layers=DECODER_LAYERS, \n",
    "        dim_feedforward=FF_DIM,\n",
    "        dropout=DROPOUT\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(model.parameters()), \n",
    "        lr=LEARNING_RATE,\n",
    "        betas=(BETA_1, BETA_2)\n",
    "    )\n",
    "    \n",
    "    model, _, _, _, _, _ = load_model_state(\n",
    "        os.path.join(CHECKPOINT_BASE, author + '_best.pt'), \n",
    "        model, \n",
    "        optimizer\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(device)\n",
    "                    \n",
    "    models.append(model)\n",
    "    print('Model checkpoint loaded for {}'.format(author))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    'The man said he was angry and wet',\n",
    "    'I don\\'t believe it Mr. Grey',\n",
    "    'random said believe man'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "\n",
    "for idx, length in enumerate(SENTENCES_LENGTHS):\n",
    "    sentences = []\n",
    "    for sentence in text:\n",
    "        # split = [vocab.START_STR]\n",
    "        split = []\n",
    "        split.extend(split_sentences(sentence)[0][:length])\n",
    "        split.extend([vocabs[idx].PAD_STR] * ( length - len(split) ))\n",
    "        split.append(vocabs[idx].END_STR)\n",
    "        split = [word.lower().strip() for word in split]\n",
    "        indices = vocabs[idx].to_indices(split)    \n",
    "        sentences.append(indices)\n",
    "        \n",
    "    batches.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Author: Ernest Hemingway\n",
      "----------------------------------------------------------------------\n",
      "Original: The man said he was angry and wet\n",
      "Input: the man said he was <unk> and wet <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "Output: the <unk> said he was <unk> and wet <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "----------------------------------------------------------------------\n",
      "Original: I don't believe it Mr. Grey\n",
      "Input: i don ' t believe it <unk> <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "Output: i don ' <unk> believe it <unk> <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "----------------------------------------------------------------------\n",
      "Original: random said believe man\n",
      "Input: <unk> said believe man <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "Output: <unk> said believe <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "**********************************************************************\n",
      "Author: Friedrich Nietzsche\n",
      "----------------------------------------------------------------------\n",
      "Original: The man said he was angry and wet\n",
      "Input: the man said he was angry and <unk> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "Output: the man said he was sweep and malady <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "----------------------------------------------------------------------\n",
      "Original: I don't believe it Mr. Grey\n",
      "Input: i don ' t believe it <unk> grey <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "Output: i malady ' t sweep it unfrequented grey <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "----------------------------------------------------------------------\n",
      "Original: random said believe man\n",
      "Input: <unk> said believe man <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "Output: unfrequented said sweep man <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "**********************************************************************\n",
      "Author: Oscar Wilde\n",
      "----------------------------------------------------------------------\n",
      "Original: The man said he was angry and wet\n",
      "Input: the man said he was angry and wet <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "Output: the man said he was angry and colourless <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "----------------------------------------------------------------------\n",
      "Original: I don't believe it Mr. Grey\n",
      "Input: i don ' t believe it mr grey <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "Output: i don ' t believe it mr grey <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "----------------------------------------------------------------------\n",
      "Original: random said believe man\n",
      "Input: <unk> said believe man <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n",
      "Output: dawned said believe man <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <eos>\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "for idx, author in enumerate(AUTHORS):\n",
    "    \n",
    "    print('**********************************************************************')\n",
    "    print('Author: {}'.format(author))\n",
    "    \n",
    "    sentences = batches[idx]\n",
    "    target = np.array([[vocabs[idx].START_TOKEN] * (SENTENCES_LENGTHS[idx] + 1)]  * len(sentences))\n",
    "    \n",
    "    for word_idx in range(SENTENCES_LENGTHS[idx]):\n",
    "        with torch.no_grad():\n",
    "            predicted = model(torch.LongTensor(sentences).to(device), torch.LongTensor(target).to(device))\n",
    "            predicted = torch.argmax(predicted, dim=2).cpu().numpy()\n",
    "\n",
    "        target[:, 1:] = predicted[:, :-1]\n",
    "\n",
    "    for jdx, sentence in enumerate(predicted):\n",
    "        print('----------------------------------------------------------------------')\n",
    "        print('Original: {}'.format(text[jdx]))\n",
    "        print('Input: {}'.format(' '.join(vocabs[idx].to_words(sentences[jdx]))))\n",
    "        print('Output: {}'.format(' '.join(vocabs[idx].to_words(sentence))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
